{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Subset\nfrom torchvision import datasets, transforms\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nimport numpy as np\n\n\n# Block definition (with optional upsampling)\nclass Block(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, upsample=False):\n        super(Block, self).__init__()\n        self.upsample = upsample\n        self.conv = nn.Conv2d(\n            in_channels,\n            out_channels,\n            kernel_size=kernel_size,\n            stride=stride,\n            padding=1,  # Ensure output size matches input size\n            bias=False\n        )\n        self.norm = nn.BatchNorm2d(out_channels)\n        self.act = nn.ReLU()\n\n    def forward(self, x):\n        if self.upsample:\n            x = nn.functional.interpolate(x, scale_factor=2, mode=\"bilinear\", align_corners=False)\n        x = self.conv(x)\n        x = self.norm(x)\n        x = self.act(x)\n        return x\n\n\n# AutoEncoder\nclass AutoEncoder(nn.Module):\n    def __init__(self, latent_dim=128):\n        super(AutoEncoder, self).__init__()\n\n        # Encoder\n        self.encoder = nn.Sequential(\n            nn.Conv2d(1, 32, kernel_size=3, stride=2, padding=1),  # 28x28 -> 14x14\n            nn.ReLU(),\n            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),  # 14x14 -> 7x7\n            nn.ReLU(),\n            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),  # 7x7 -> 4x4\n            nn.ReLU(),\n        )\n\n        # Bottleneck (latent space)\n        self.bottleneck = nn.Sequential(\n            nn.Flatten(),\n            nn.Linear(128 * 4 * 4, latent_dim),  # Embedding into a 128-dimensional space\n        )\n\n     \n        self.decoder = nn.Sequential(\n            Block(128, 64, upsample=True),  # 4x4 -> 8x8\n            Block(64, 32, upsample=True),   # 8x8 -> 16x16\n            Block(32, 16, upsample=True),   # 16x16 -> 32x32\n            nn.Conv2d(16, 1, kernel_size=3, padding=1),  # 32x32 -> 28x28 (restore original size)\n            nn.Sigmoid(),\n        )\n\n    def forward(self, x):\n        x = self.encoder(x)\n        x = self.bottleneck(x)\n        x = x.unsqueeze(-1).unsqueeze(-1)  # Reshaping for decoder\n        x = self.decoder(x)\n\n        # Resize to ensure the output is exactly 28x28\n        x = nn.functional.interpolate(x, size=(28, 28), mode=\"bilinear\", align_corners=False)\n        return x\n\n    @torch.no_grad()\n    def encode(self, x):\n        x = self.encoder(x)  # Получаем закодированное представление (размерность [batch_size, 128, 4, 4])\n        x = x.flatten(start_dim=1)  # Преобразуем в 1D вектор с размерностью [batch_size, 2048]\n        x = self.bottleneck(x)  # Проходим через слой bottleneck, чтобы получить эмбеддинг размером [batch_size, 128]\n        return x  # Возвращаем эмбеддинг размерности [batch_size, 128]\n\n\n\n# Save embeddings function\ndef save_embeddings(x_train, y_train, x_valid, y_valid):\n    assert x_train.shape[0] == 1000\n    assert x_valid.shape[0] == 10000\n    assert y_train.shape[0] == 1000\n    assert y_valid.shape[0] == 10000\n\n    torch.save(\n        {\n            'x_train': x_train,\n            'y_train': y_train,\n            'x_valid': x_valid,\n            'y_valid': y_valid\n        },\n        'embeddings2.pt'\n    )\n\n\n# Main function\ndef main():\n    # Dataset and Dataloader\n    transform = transforms.Compose([transforms.ToTensor()])\n    train_data = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n    test_data = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n\n    train_subset = Subset(train_data, range(1000))\n    train_loader = DataLoader(train_subset, batch_size=64, shuffle=True)\n    test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n\n    # Model setup\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    autoencoder = AutoEncoder(latent_dim=128).to(device)\n    optimizer = optim.Adam(autoencoder.parameters(), lr=1e-3)\n    criterion = nn.MSELoss()\n\n    for epoch in range(45):\n        # Train AutoEncoder\n        autoencoder.train()\n        epoch_loss = 0\n        for images, _ in train_loader:\n            images = images.to(device)\n            optimizer.zero_grad()\n            outputs = autoencoder(images)\n            loss = criterion(outputs, images)\n            loss.backward()\n            optimizer.step()\n            epoch_loss += loss.item()\n        print(f\"Epoch {epoch + 1}, Loss: {epoch_loss / len(train_loader):.4f}\")\n\n        # Generate embeddings for training and testing data\n        autoencoder.eval()\n        train_embeddings, train_labels = [], []\n        test_embeddings, test_labels = [], []\n\n        with torch.no_grad():\n            for images, labels in train_loader:\n                images = images.to(device)\n                embeddings = autoencoder.encode(images).cpu().numpy()  # Get the feature maps\n                train_embeddings.append(embeddings)  # No need to reshape, as embeddings are already flat\n                train_labels.append(labels.numpy())\n\n            for images, labels in test_loader:\n                images = images.to(device)\n                embeddings = autoencoder.encode(images).cpu().numpy()  # Get the feature maps\n                test_embeddings.append(embeddings)  # No need to reshape, as embeddings are already flat\n                test_labels.append(labels.numpy())\n\n        train_embeddings = np.vstack(train_embeddings)\n        train_labels = np.concatenate(train_labels)\n        test_embeddings = np.vstack(test_embeddings)\n        test_labels = np.concatenate(test_labels)\n\n        # Train Random Forest\n        clf = RandomForestClassifier(random_state=0)  # Hyperparameters for improvement\n        clf.fit(train_embeddings, train_labels)\n\n        # Evaluate\n        predictions = clf.predict(test_embeddings)\n        accuracy = accuracy_score(test_labels, predictions)\n        print(f\"Epoch {epoch + 1}, Test Accuracy: {accuracy * 100:.2f}%\")\n\n        if accuracy > 0.90:\n            print(\"Accuracy exceeded 90%, stopping training.\")\n            break\n\n\n    # Save embeddings\n    save_embeddings(\n        x_train=torch.tensor(train_embeddings, dtype=torch.float16),\n        y_train=torch.tensor(train_labels, dtype=torch.int32),\n        x_valid=torch.tensor(test_embeddings, dtype=torch.float16),\n        y_valid=torch.tensor(test_labels, dtype=torch.int32),\n    )\n\n\nif __name__ == \"__main__\":\n    main()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T14:43:57.123128Z","iopub.execute_input":"2025-01-11T14:43:57.123348Z","iopub.status.idle":"2025-01-11T14:45:23.993321Z","shell.execute_reply.started":"2025-01-11T14:43:57.123326Z","shell.execute_reply":"2025-01-11T14:45:23.992378Z"}},"outputs":[{"name":"stdout","text":"Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\nFailed to download (trying next):\nHTTP Error 403: Forbidden\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 9912422/9912422 [00:00<00:00, 16099634.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\nFailed to download (trying next):\nHTTP Error 403: Forbidden\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 28881/28881 [00:00<00:00, 471323.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\nFailed to download (trying next):\nHTTP Error 403: Forbidden\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1648877/1648877 [00:00<00:00, 4480637.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\nFailed to download (trying next):\nHTTP Error 403: Forbidden\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4542/4542 [00:00<00:00, 7240793.91it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n\nEpoch 1, Loss: 0.1455\nEpoch 1, Test Accuracy: 73.31%\nEpoch 2, Loss: 0.0839\nEpoch 2, Test Accuracy: 73.26%\nEpoch 3, Loss: 0.0701\nEpoch 3, Test Accuracy: 74.19%\nEpoch 4, Loss: 0.0642\nEpoch 4, Test Accuracy: 77.73%\nEpoch 5, Loss: 0.0605\nEpoch 5, Test Accuracy: 80.59%\nEpoch 6, Loss: 0.0574\nEpoch 6, Test Accuracy: 82.05%\nEpoch 7, Loss: 0.0548\nEpoch 7, Test Accuracy: 83.51%\nEpoch 8, Loss: 0.0527\nEpoch 8, Test Accuracy: 84.45%\nEpoch 9, Loss: 0.0509\nEpoch 9, Test Accuracy: 85.25%\nEpoch 10, Loss: 0.0490\nEpoch 10, Test Accuracy: 86.15%\nEpoch 11, Loss: 0.0472\nEpoch 11, Test Accuracy: 86.62%\nEpoch 12, Loss: 0.0462\nEpoch 12, Test Accuracy: 86.75%\nEpoch 13, Loss: 0.0453\nEpoch 13, Test Accuracy: 87.52%\nEpoch 14, Loss: 0.0443\nEpoch 14, Test Accuracy: 87.76%\nEpoch 15, Loss: 0.0434\nEpoch 15, Test Accuracy: 87.77%\nEpoch 16, Loss: 0.0426\nEpoch 16, Test Accuracy: 87.67%\nEpoch 17, Loss: 0.0418\nEpoch 17, Test Accuracy: 88.44%\nEpoch 18, Loss: 0.0411\nEpoch 18, Test Accuracy: 88.24%\nEpoch 19, Loss: 0.0410\nEpoch 19, Test Accuracy: 88.28%\nEpoch 20, Loss: 0.0403\nEpoch 20, Test Accuracy: 88.57%\nEpoch 21, Loss: 0.0397\nEpoch 21, Test Accuracy: 88.91%\nEpoch 22, Loss: 0.0396\nEpoch 22, Test Accuracy: 89.10%\nEpoch 23, Loss: 0.0393\nEpoch 23, Test Accuracy: 88.88%\nEpoch 24, Loss: 0.0386\nEpoch 24, Test Accuracy: 89.46%\nEpoch 25, Loss: 0.0385\nEpoch 25, Test Accuracy: 89.50%\nEpoch 26, Loss: 0.0381\nEpoch 26, Test Accuracy: 89.43%\nEpoch 27, Loss: 0.0377\nEpoch 27, Test Accuracy: 89.64%\nEpoch 28, Loss: 0.0377\nEpoch 28, Test Accuracy: 89.44%\nEpoch 29, Loss: 0.0373\nEpoch 29, Test Accuracy: 89.82%\nEpoch 30, Loss: 0.0371\nEpoch 30, Test Accuracy: 89.86%\nEpoch 31, Loss: 0.0369\nEpoch 31, Test Accuracy: 89.80%\nEpoch 32, Loss: 0.0368\nEpoch 32, Test Accuracy: 89.53%\nEpoch 33, Loss: 0.0367\nEpoch 33, Test Accuracy: 89.90%\nEpoch 34, Loss: 0.0365\nEpoch 34, Test Accuracy: 89.49%\nEpoch 35, Loss: 0.0364\nEpoch 35, Test Accuracy: 90.15%\nAccuracy exceeded 90%, stopping training.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}