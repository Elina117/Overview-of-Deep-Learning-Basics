{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Напишите функцию для подсчета количества параметров в сверточном слое. Ваша функция должна принимать на вход количество входных каналов, количество выходных каналов, размер ядра и стоит ли делать обучаемый сдвиг. Сделайте для нее такую сигнатуру: def count_parameters_conv(in_channels: int, out_channels: int, kernel_size: int, bias: bool):","metadata":{}},{"cell_type":"code","source":"def count_parameters_conv(in_channels: int, out_channels: int, kernel_size: int, bias: bool):\n     # Подсчет параметров для весов и сдвига по формуле: (C1 * n^2 + 1) * C2\n    num_parameters = (in_channels * kernel_size**2) * out_channels\n    return num_parameters","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Обучите полносвязную нейронную сеть для классификации на датасете MNIST. Добейтесь качества в 98% на тестовой выборке.\n\nМожете использовать уже написанные ранее функции train и evaluate.\n\nЧтобы мы могли проверить вашу модель, напишите функцию, которая создает вашу модель и возвращает объект, назовите функцию create_mlp_model, без аргументов. Вам понадобится сохранить веса вашей модели и сдать их в тестировщик, для этого воспользуйтесь методами torch.save и state_dict.\n\nЧекер ожидает от вас два файла. Первый файл с функцией create_mlp_model в формате .py. Второй файл с весами в формате .pt.\n\n","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.optim as optim\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms\nimport torchvision.transforms as T\nfrom torch.optim import Optimizer, Adam\n\n\n\ndef train(model: nn.Module, data_loader: DataLoader, optimizer: Optimizer, loss_fn) -> tuple[float, float]:\n    model.train()\n\n    total_loss = 0\n    total = 0\n    correct = 0\n\n    for x, y in tqdm(data_loader, desc='Train'):\n        optimizer.zero_grad()\n\n        output = model(x)\n\n        loss = loss_fn(output, y)\n\n        loss.backward()\n\n        total_loss += loss.item()\n\n        optimizer.step()\n\n        _, y_pred = torch.max(output, 1)\n        total += y.size(0)\n        correct += (y_pred == y).sum().item()\n\n    return total_loss / len(data_loader), correct / total","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T13:54:18.576930Z","iopub.execute_input":"2024-12-16T13:54:18.577635Z","iopub.status.idle":"2024-12-16T13:54:22.410612Z","shell.execute_reply.started":"2024-12-16T13:54:18.577599Z","shell.execute_reply":"2024-12-16T13:54:22.409734Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"def evaluate(model: nn.Module, data_loader: DataLoader, loss_fn) -> tuple[float, float]:\n    model.eval()\n\n    total_loss = 0\n    total = 0\n    correct = 0\n\n    for x, y in tqdm(data_loader, desc='Evaluate'):\n        output = model(x)\n\n        loss = loss_fn(output, y)\n\n        total_loss += loss.item()\n\n        _, y_pred = torch.max(output, 1)\n        total += y.size(0)\n        correct += (y_pred == y).sum().item()\n\n    return total_loss / len(data_loader), correct / total","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T13:54:25.701845Z","iopub.execute_input":"2024-12-16T13:54:25.702330Z","iopub.status.idle":"2024-12-16T13:54:25.708038Z","shell.execute_reply.started":"2024-12-16T13:54:25.702295Z","shell.execute_reply":"2024-12-16T13:54:25.706991Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"from torch import nn\n\ndef create_mlp_model():\n    model = nn.Sequential(\n        nn.Flatten(),  # Преобразуем изображение 28x28 в вектор длины 784\n        nn.Linear(28 * 28, 512),  # Первый скрытый слой\n        nn.ReLU(),  # Функция активации ReLU\n        nn.Linear(512, 256),  # Второй скрытый слой\n        nn.ReLU(),  # Функция активации ReLU\n        nn.Linear(256, 10)  # Выходной слой для 10 классов\n    )\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T21:09:17.466779Z","iopub.execute_input":"2024-12-15T21:09:17.467134Z","iopub.status.idle":"2024-12-15T21:09:17.472520Z","shell.execute_reply.started":"2024-12-15T21:09:17.467103Z","shell.execute_reply":"2024-12-15T21:09:17.471643Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"from tqdm import tqdm\n\n# Загружаем тренировочные и тестовые данные\ntrain_dataset = datasets.MNIST(root=\"../datasets/mnist\",\n                               train=True,\n                               download=True,\n                               transform=T.ToTensor())\n\ntest_dataset = datasets.MNIST(root=\"../datasets/mnist\",\n                              train=False,\n                              download=True,\n                              transform=T.ToTensor())\n\n\ntrain_loader = DataLoader(train_dataset,\n                          batch_size=64,\n                          shuffle=True)\n\ntest_loader = DataLoader(test_dataset,\n                          batch_size=64,\n                          shuffle=False)\n\n\nmodel = create_mlp_model()\n\n# Определяем функцию потерь и оптимизатор\nloss_fn = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n\n#Train the model\nfor epoch in range(10):\n    train_loss, train_accuracy = train(model, train_loader, optimizer, loss_fn)\n    print(f\"Epoch {epoch+1}: Train Loss = {train_loss:.4f}, Train Accuracy = {train_accuracy}%\")\n\n# Оценка модели на тестовой выборке\ntest_loss, test_accuracy = evaluate(model, test_loader, loss_fn)\nprint(f\"Test Loss = {test_loss}, Test Accuracy = {test_accuracy}\")","metadata":{"trusted":true},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Loss = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mtest_loss\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Test Accuracy = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_accuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mNameError\u001b[0m: name 'test_loss' is not defined"],"ename":"NameError","evalue":"name 'test_loss' is not defined","output_type":"error"}],"execution_count":5},{"cell_type":"code","source":"# Сохраняем веса модели в директории /kaggle/working/\ntorch.save(model.state_dict(), '/kaggle/working/mnist_mlp_model.pth')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-15T21:14:29.431389Z","iopub.execute_input":"2024-12-15T21:14:29.431746Z","iopub.status.idle":"2024-12-15T21:14:29.440094Z","shell.execute_reply.started":"2024-12-15T21:14:29.431715Z","shell.execute_reply":"2024-12-15T21:14:29.439204Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"Обучите сверточную нейронную сеть для классификации на датасете MNIST. Добейтесь качества в 99.3% на тестовой выборке.\n\nМожете использовать уже написанные ранее функции train и evaluate.\n\nЧтобы мы могли проверить вашу модель, напишите функцию, которая создает вашу модель и возвращает объект, назовите функцию create_conv_model, без аргументов. Вам понадобится сохранить веса вашей модели и сдать их в тестировщик, для этого воспользуйтесь методами torch.save и state_dict.","metadata":{}},{"cell_type":"code","source":"from torch import nn\n\ndef create_conv_model():\n    model = nn.Sequential(\n        # Первый сверточный слой\n        nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1),  # Padding чтобы сохранить размер\n        nn.ReLU(),\n        nn.MaxPool2d(kernel_size=2, stride=2),\n\n        # Второй сверточный слой\n        nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),  # Padding чтобы сохранить размер\n        nn.ReLU(),\n        nn.MaxPool2d(kernel_size=2, stride=2),\n\n        # Третий сверточный слой\n        nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),  # Padding чтобы сохранить размер\n        nn.ReLU(),\n        nn.MaxPool2d(kernel_size=2, stride=2),\n\n        # Четвертый сверточный слой\n        nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),  # Padding чтобы сохранить размер\n        nn.ReLU(),\n        nn.MaxPool2d(kernel_size=2, stride=2),\n        \n        # Полносвязные слои\n        nn.Flatten(),\n        nn.Linear(256 * 1 * 1, 512),  # Уменьшили размер после последнего слоя свертки\n        nn.ReLU(),\n        nn.Linear(512, 10)  # 10 классов для MNIST\n    )\n    return model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T14:36:04.453812Z","iopub.execute_input":"2024-12-16T14:36:04.454146Z","iopub.status.idle":"2024-12-16T14:36:04.461203Z","shell.execute_reply.started":"2024-12-16T14:36:04.454116Z","shell.execute_reply":"2024-12-16T14:36:04.460226Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"from tqdm import tqdm\n\n# Загружаем тренировочные и тестовые данные\ntrain_dataset = datasets.MNIST(root=\"../datasets/mnist\",\n                               train=True,\n                               download=True,\n                               transform=T.ToTensor())\n\ntest_dataset = datasets.MNIST(root=\"../datasets/mnist\",\n                              train=False,\n                              download=True,\n                              transform=T.ToTensor())\n\ntrain_loader = DataLoader(train_dataset,\n                         batch_size=64,\n                         shuffle=True)\n\ntest_loader = DataLoader(test_dataset,\n                        batch_size=64,\n                        shuffle=False)\n\nmodel = create_conv_model()\n\nloss_fn = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.0005)\n\nfor epoch in range(20):\n    train_loss, train_accuracy = train(model, train_loader, optimizer, loss_fn)\n    print(f\"Epoch {epoch+1}: Train Loss = {train_loss:.4f}, Train Accuracy = {train_accuracy}\")\n\n\ntest_loss, test_accuracy = evaluate(model, test_loader, loss_fn)\nprint(f\"Test Loss = {test_loss}, Test Accuracy = {test_accuracy}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T14:36:10.290480Z","iopub.execute_input":"2024-12-16T14:36:10.291368Z","iopub.status.idle":"2024-12-16T14:52:39.487350Z","shell.execute_reply.started":"2024-12-16T14:36:10.291327Z","shell.execute_reply":"2024-12-16T14:52:39.486514Z"}},"outputs":[{"name":"stderr","text":"Train: 100%|██████████| 938/938 [00:48<00:00, 19.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1: Train Loss = 0.2517, Train Accuracy = 0.9186833333333333\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 938/938 [00:48<00:00, 19.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2: Train Loss = 0.0605, Train Accuracy = 0.9816333333333334\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 938/938 [00:48<00:00, 19.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3: Train Loss = 0.0413, Train Accuracy = 0.9868666666666667\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 938/938 [00:48<00:00, 19.48it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4: Train Loss = 0.0311, Train Accuracy = 0.9904\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 938/938 [00:49<00:00, 19.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5: Train Loss = 0.0254, Train Accuracy = 0.9919333333333333\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 938/938 [00:48<00:00, 19.26it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6: Train Loss = 0.0207, Train Accuracy = 0.9931333333333333\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 938/938 [00:48<00:00, 19.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7: Train Loss = 0.0171, Train Accuracy = 0.9943666666666666\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 938/938 [00:50<00:00, 18.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8: Train Loss = 0.0143, Train Accuracy = 0.9954666666666667\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 938/938 [00:50<00:00, 18.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9: Train Loss = 0.0125, Train Accuracy = 0.9959\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 938/938 [00:49<00:00, 18.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10: Train Loss = 0.0098, Train Accuracy = 0.9970166666666667\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 938/938 [00:48<00:00, 19.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 11: Train Loss = 0.0104, Train Accuracy = 0.9968166666666667\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 938/938 [00:48<00:00, 19.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 12: Train Loss = 0.0083, Train Accuracy = 0.9973833333333333\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 938/938 [00:49<00:00, 18.92it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 13: Train Loss = 0.0074, Train Accuracy = 0.9976\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 938/938 [00:49<00:00, 18.91it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 14: Train Loss = 0.0063, Train Accuracy = 0.99815\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 938/938 [00:48<00:00, 19.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 15: Train Loss = 0.0080, Train Accuracy = 0.9973166666666666\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 938/938 [00:49<00:00, 18.96it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 16: Train Loss = 0.0063, Train Accuracy = 0.9978333333333333\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 938/938 [00:49<00:00, 18.94it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 17: Train Loss = 0.0057, Train Accuracy = 0.9982166666666666\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 938/938 [00:50<00:00, 18.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 18: Train Loss = 0.0047, Train Accuracy = 0.9985833333333334\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 938/938 [00:50<00:00, 18.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 19: Train Loss = 0.0056, Train Accuracy = 0.9980666666666667\n","output_type":"stream"},{"name":"stderr","text":"Train: 100%|██████████| 938/938 [00:48<00:00, 19.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 20: Train Loss = 0.0041, Train Accuracy = 0.99865\n","output_type":"stream"},{"name":"stderr","text":"Evaluate: 100%|██████████| 157/157 [00:03<00:00, 42.09it/s]","output_type":"stream"},{"name":"stdout","text":"Test Loss = 0.030202927676024553, Test Accuracy = 0.9936\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"torch.save(model.state_dict(), '/kaggle/working/mnist_mlp_model_5.pt')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T15:22:21.962963Z","iopub.execute_input":"2024-12-16T15:22:21.963305Z","iopub.status.idle":"2024-12-16T15:22:21.972260Z","shell.execute_reply.started":"2024-12-16T15:22:21.963273Z","shell.execute_reply":"2024-12-16T15:22:21.971302Z"}},"outputs":[],"execution_count":19}]}